{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Gemma 3 fine-tuning using Hugging Face\n\nIn this notebook, we're going to fine tune Gemma 3 [google/gemma-3-1b-it](https://huggingface.co/google/gemma-3-1b-it) on the [Natural Language to Regex dataset](https://huggingface.co/datasets/inclinedadarsh/nl-to-regex)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:49:23.625499Z","iopub.execute_input":"2025-03-24T10:49:23.625811Z","iopub.status.idle":"2025-03-24T10:49:24.765251Z","shell.execute_reply.started":"2025-03-24T10:49:23.625780Z","shell.execute_reply":"2025-03-24T10:49:24.764598Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Installing the required libraries","metadata":{}},{"cell_type":"code","source":"%pip install \"torch>2.3.0\" wandb\n\n%pip install git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\n\n%pip install -U datasets accelerate evaluate bitsandbytes peft trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:50:37.003166Z","iopub.execute_input":"2025-03-24T10:50:37.003499Z","iopub.status.idle":"2025-03-24T10:51:23.403255Z","shell.execute_reply.started":"2025-03-24T10:50:37.003473Z","shell.execute_reply":"2025-03-24T10:51:23.402454Z"},"jupyter":{"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch>2.3.0 in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>2.3.0) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>2.3.0) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>2.3.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>2.3.0) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>2.3.0) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>2.3.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>2.3.0) (1.3.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>2.3.0) (3.0.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\nCollecting git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\n  Cloning https://github.com/huggingface/transformers (to revision v4.49.0-Gemma-3) to /tmp/pip-req-build-m7_2f53s\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-m7_2f53s\n  Running command git checkout -q 367bab469b0ef32017e2a0a0a5dbac5d36002f03\n  Resolved https://github.com/huggingface/transformers to commit 367bab469b0ef32017e2a0a0a5dbac5d36002f03\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.50.0.dev0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.50.0.dev0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.50.0.dev0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.50.0.dev0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.50.0.dev0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.50.0.dev0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers==4.50.0.dev0) (2024.2.0)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for transformers: filename=transformers-4.50.0.dev0-py3-none-any.whl size=10936468 sha256=54103165a8b1c12ea09241ac79cf7d20c9a321a0cb9e6eeefde8b0d97c11d745\n  Stored in directory: /tmp/pip-ephem-wheel-cache-z8enl_m6/wheels/c1/95/d1/7d800368ab25942bf88f88fe1716597fcc8d757043c9b48a2f\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\nSuccessfully installed transformers-4.50.0.dev0\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting datasets\n  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nCollecting accelerate\n  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nCollecting peft\n  Downloading peft-0.15.0-py3-none-any.whl.metadata (13 kB)\nCollecting trl\n  Downloading trl-0.16.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.50.0.dev0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading datasets-3.4.1-py3-none-any.whl (487 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.15.0-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.8/410.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.16.0-py3-none-any.whl (335 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: datasets, accelerate, trl, peft, evaluate, bitsandbytes\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.3.1\n    Uninstalling datasets-3.3.1:\n      Successfully uninstalled datasets-3.3.1\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.2.1\n    Uninstalling accelerate-1.2.1:\n      Successfully uninstalled accelerate-1.2.1\n  Attempting uninstall: peft\n    Found existing installation: peft 0.14.0\n    Uninstalling peft-0.14.0:\n      Successfully uninstalled peft-0.14.0\nSuccessfully installed accelerate-1.5.2 bitsandbytes-0.45.3 datasets-3.4.1 evaluate-0.4.3 peft-0.15.0 trl-0.16.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Making necessary configs","metadata":{}},{"cell_type":"code","source":"# Loading the secrets from kaggle\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\") # Make sure the HF_TOKEN has read and write access (write access to push the model to hub)\nWANDB_KEY = user_secrets.get_secret(\"WANDB_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:51:51.732276Z","iopub.execute_input":"2025-03-24T10:51:51.732661Z","iopub.status.idle":"2025-03-24T10:51:51.998215Z","shell.execute_reply.started":"2025-03-24T10:51:51.732634Z","shell.execute_reply":"2025-03-24T10:51:51.997403Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(HF_TOKEN)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:51:53.655737Z","iopub.execute_input":"2025-03-24T10:51:53.656049Z","iopub.status.idle":"2025-03-24T10:51:54.467209Z","shell.execute_reply.started":"2025-03-24T10:51:53.656023Z","shell.execute_reply":"2025-03-24T10:51:54.466587Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import wandb\nwandb.login(key=WANDB_KEY)\nwandb.init(project=\"gemma-3-finetune\", name=\"second-run\")\n# Initialize the wandb project here","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:52:23.222725Z","iopub.execute_input":"2025-03-24T10:52:23.223243Z","iopub.status.idle":"2025-03-24T10:52:29.346293Z","shell.execute_reply.started":"2025-03-24T10:52:23.223212Z","shell.execute_reply":"2025-03-24T10:52:29.345575Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250324_105223-nyqiwxm7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/inclinedadarsh-kk-wagh-institute/gemma-3-finetune/runs/nyqiwxm7' target=\"_blank\">second-run</a></strong> to <a href='https://wandb.ai/inclinedadarsh-kk-wagh-institute/gemma-3-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/inclinedadarsh-kk-wagh-institute/gemma-3-finetune' target=\"_blank\">https://wandb.ai/inclinedadarsh-kk-wagh-institute/gemma-3-finetune</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/inclinedadarsh-kk-wagh-institute/gemma-3-finetune/runs/nyqiwxm7' target=\"_blank\">https://wandb.ai/inclinedadarsh-kk-wagh-institute/gemma-3-finetune/runs/nyqiwxm7</a>"},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/inclinedadarsh-kk-wagh-institute/gemma-3-finetune/runs/nyqiwxm7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x794b223a8a00>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Getting the dataset read\n\nLet's get the dataset ready, with the help of `load_dataset` function from the `datasets` library. We'll be loading the `inclinedadarsh/nl-to-regex` dataset.","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:52:57.904977Z","iopub.execute_input":"2025-03-24T10:52:57.905332Z","iopub.status.idle":"2025-03-24T10:52:58.532874Z","shell.execute_reply.started":"2025-03-24T10:52:57.905305Z","shell.execute_reply":"2025-03-24T10:52:58.532227Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"dataset = load_dataset('inclinedadarsh/nl-to-regex')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:53:10.949616Z","iopub.execute_input":"2025-03-24T10:53:10.950219Z","iopub.status.idle":"2025-03-24T10:53:13.780220Z","shell.execute_reply.started":"2025-03-24T10:53:10.950183Z","shell.execute_reply":"2025-03-24T10:53:13.779397Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79349f628d1845c5b379bf87140dd81a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset.csv:   0%|          | 0.00/53.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f8db0d6250c41f6948852d8f06921f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/824 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87d55dadb0e9421e86dc1ec0a9ed96c5"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"system_message = \"You are a helpful natural language to regex converter. The user will provide some prompt, and you have to create a regex according to it.\"\n\ndef format_example(example):\n    return {\n        \"messages\": [\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": example['user']},\n            {\"role\": \"assistant\", \"content\": example['assistant']}\n        ]\n    }\n\ndataset = dataset.map(format_example, remove_columns=dataset['train'].features, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:53:59.527703Z","iopub.execute_input":"2025-03-24T10:53:59.528022Z","iopub.status.idle":"2025-03-24T10:53:59.595741Z","shell.execute_reply.started":"2025-03-24T10:53:59.527987Z","shell.execute_reply":"2025-03-24T10:53:59.594883Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/824 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfe8ba6c998f42aeb81f034a01c4b783"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:54:11.906439Z","iopub.execute_input":"2025-03-24T10:54:11.906729Z","iopub.status.idle":"2025-03-24T10:54:19.080244Z","shell.execute_reply.started":"2025-03-24T10:54:11.906708Z","shell.execute_reply":"2025-03-24T10:54:19.079625Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model_name = 'google/gemma-3-1b-it'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:54:22.574794Z","iopub.execute_input":"2025-03-24T10:54:22.575405Z","iopub.status.idle":"2025-03-24T10:54:22.579752Z","shell.execute_reply.started":"2025-03-24T10:54:22.575368Z","shell.execute_reply":"2025-03-24T10:54:22.578946Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_quant_storage=torch.float16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:54:24.109208Z","iopub.execute_input":"2025-03-24T10:54:24.109518Z","iopub.status.idle":"2025-03-24T10:54:24.115739Z","shell.execute_reply.started":"2025-03-24T10:54:24.109494Z","shell.execute_reply":"2025-03-24T10:54:24.114929Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    attn_implementation='eager',\n    quantization_config=bnb_config,\n    torch_dtype=torch.float16,\n    device_map='auto'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:54:26.974753Z","iopub.execute_input":"2025-03-24T10:54:26.975072Z","iopub.status.idle":"2025-03-24T10:54:53.814227Z","shell.execute_reply.started":"2025-03-24T10:54:26.975045Z","shell.execute_reply":"2025-03-24T10:54:53.813318Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/899 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22acc25633884aeb8575e29d85f060d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22dab219355a4462894cd59ee86ea534"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"344026dcc4a5436a9711c0a91a621d55"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:55:08.643810Z","iopub.execute_input":"2025-03-24T10:55:08.644538Z","iopub.status.idle":"2025-03-24T10:55:12.068032Z","shell.execute_reply.started":"2025-03-24T10:55:08.644506Z","shell.execute_reply":"2025-03-24T10:55:12.067136Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b324373c7a442c7b9921337f5eccdac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efc5fbd2ced540f3a3a76797e935c0fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53350aa5b0d943a692c0119acfce63a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86eb1ba42f614e94930a5bb61c849a6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"535d134b03074105adc23dee8b19c83a"}},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"## Setting up LoRA parameteres for parameters efficient fine tuning","metadata":{"execution":{"iopub.status.busy":"2025-03-24T10:55:50.297545Z","iopub.execute_input":"2025-03-24T10:55:50.297837Z","iopub.status.idle":"2025-03-24T10:55:50.301771Z","shell.execute_reply.started":"2025-03-24T10:55:50.297813Z","shell.execute_reply":"2025-03-24T10:55:50.301020Z"}}},{"cell_type":"code","source":"from peft import LoraConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:55:55.047821Z","iopub.execute_input":"2025-03-24T10:55:55.048116Z","iopub.status.idle":"2025-03-24T10:55:55.132685Z","shell.execute_reply.started":"2025-03-24T10:55:55.048092Z","shell.execute_reply":"2025-03-24T10:55:55.132024Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"peft_config = LoraConfig(\n    lora_alpha=8,\n    lora_dropout=0.05,\n    r=8,\n    bias=\"none\",\n    target_modules='all-linear',\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:55:55.545385Z","iopub.execute_input":"2025-03-24T10:55:55.545642Z","iopub.status.idle":"2025-03-24T10:55:55.550425Z","shell.execute_reply.started":"2025-03-24T10:55:55.545622Z","shell.execute_reply":"2025-03-24T10:55:55.549581Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Setting up the training arguments","metadata":{}},{"cell_type":"code","source":"from trl import SFTConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:56:05.389877Z","iopub.execute_input":"2025-03-24T10:56:05.390172Z","iopub.status.idle":"2025-03-24T10:56:05.420972Z","shell.execute_reply.started":"2025-03-24T10:56:05.390149Z","shell.execute_reply":"2025-03-24T10:56:05.420369Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"training_args = SFTConfig(\n    output_dir=\"./gemma-finetune\",\n    max_seq_length=512,\n    packing=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    gradient_checkpointing=True,\n    optim='adamw_torch_fused',\n    logging_steps=2,\n    save_strategy='epoch',\n    learning_rate=2e-4,\n    fp16=True,\n    max_grad_norm=0.3,\n    warmup_ratio=0.03,\n    lr_scheduler_type='constant',\n    push_to_hub=False,\n    report_to='wandb',\n    dataset_kwargs={\n        \"add_special_tokens\": False,\n        \"append_concat_token\": True\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:56:05.993900Z","iopub.execute_input":"2025-03-24T10:56:05.994194Z","iopub.status.idle":"2025-03-24T10:56:06.028407Z","shell.execute_reply.started":"2025-03-24T10:56:05.994174Z","shell.execute_reply":"2025-03-24T10:56:06.027777Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from trl import SFTTrainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:56:13.226659Z","iopub.execute_input":"2025-03-24T10:56:13.226957Z","iopub.status.idle":"2025-03-24T10:56:14.339078Z","shell.execute_reply.started":"2025-03-24T10:56:13.226935Z","shell.execute_reply":"2025-03-24T10:56:14.338408Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    args=training_args,\n    peft_config=peft_config,\n    processing_class=tokenizer,\n    train_dataset=dataset['train']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:56:29.723262Z","iopub.execute_input":"2025-03-24T10:56:29.723614Z","iopub.status.idle":"2025-03-24T10:56:31.362029Z","shell.execute_reply.started":"2025-03-24T10:56:29.723586Z","shell.execute_reply":"2025-03-24T10:56:31.360969Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/824 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63fe505fece245bab123f5bd8655a6d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/824 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54a9224de114d7b89cf51a22e7bebda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/824 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8aaa72c333514df2896279cb0adb7a5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Packing train dataset:   0%|          | 0/824 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24514943979a4ad3960aa69ccace4aac"}},"metadata":{}},{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## Let's train!","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T10:56:41.721451Z","iopub.execute_input":"2025-03-24T10:56:41.721752Z","iopub.status.idle":"2025-03-24T10:59:34.723117Z","shell.execute_reply.started":"2025-03-24T10:56:41.721728Z","shell.execute_reply":"2025-03-24T10:59:34.722249Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [75/75 02:49, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>2</td>\n      <td>4.060800</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.074400</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.651600</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.406200</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.273400</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.079200</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.795200</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.634200</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.447600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.328100</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.251300</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.059300</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.054600</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.937700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.786000</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.684500</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.705800</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.601400</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.572700</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.567500</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.630600</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.508500</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.565000</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.539600</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.568300</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.518700</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.506800</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.500200</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.476600</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.472600</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.446900</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.430500</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.430200</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.451600</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.430900</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.414100</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.396200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=75, training_loss=1.0530573407808939, metrics={'train_runtime': 172.5795, 'train_samples_per_second': 1.79, 'train_steps_per_second': 0.435, 'total_flos': 642734385911808.0, 'train_loss': 1.0530573407808939})"},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"## Pushing the model to hugging face hub","metadata":{}},{"cell_type":"code","source":"trainer.push_to_hub(\"inclinedadarsh/gemma-3-1b-it-nl-to-regex\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:00:07.371495Z","iopub.execute_input":"2025-03-24T11:00:07.371864Z","iopub.status.idle":"2025-03-24T11:00:13.366874Z","shell.execute_reply.started":"2025-03-24T11:00:07.371838Z","shell.execute_reply":"2025-03-24T11:00:13.366148Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db6987105abd41678cfeaf3fb818709f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"418c1c335f3f4baaa2562dc774700fb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fb83af09e7d4420aed0dedd6617b061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/26.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19778e7acd864c0a8adb822109fd1096"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bba84d7ef9b94aaf8db997390d09c8f0"}},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/inclinedadarsh/gemma-finetune/commit/10cc112fb85693e16c7cd956a29fd46283c3811e', commit_message='inclinedadarsh/gemma-3-1b-it-nl-to-regex', commit_description='', oid='10cc112fb85693e16c7cd956a29fd46283c3811e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/inclinedadarsh/gemma-finetune', endpoint='https://huggingface.co', repo_type='model', repo_id='inclinedadarsh/gemma-finetune'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"## Inference from the model","metadata":{"execution":{"iopub.status.busy":"2025-03-24T11:01:34.206146Z","iopub.execute_input":"2025-03-24T11:01:34.206487Z","iopub.status.idle":"2025-03-24T11:01:34.210795Z","shell.execute_reply.started":"2025-03-24T11:01:34.206460Z","shell.execute_reply":"2025-03-24T11:01:34.209956Z"}}},{"cell_type":"markdown","source":"### Before inferencing, let's free up the memory","metadata":{}},{"cell_type":"code","source":"del model\ndel trainer\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:01:48.892780Z","iopub.execute_input":"2025-03-24T11:01:48.893115Z","iopub.status.idle":"2025-03-24T11:01:48.928040Z","shell.execute_reply.started":"2025-03-24T11:01:48.893088Z","shell.execute_reply":"2025-03-24T11:01:48.927398Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"### Inference pipeline","metadata":{"execution":{"iopub.status.busy":"2025-03-24T11:01:58.995696Z","iopub.execute_input":"2025-03-24T11:01:58.995986Z","iopub.status.idle":"2025-03-24T11:01:59.000510Z","shell.execute_reply.started":"2025-03-24T11:01:58.995965Z","shell.execute_reply":"2025-03-24T11:01:58.999674Z"}}},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:02:02.325018Z","iopub.execute_input":"2025-03-24T11:02:02.325319Z","iopub.status.idle":"2025-03-24T11:02:02.459834Z","shell.execute_reply.started":"2025-03-24T11:02:02.325298Z","shell.execute_reply":"2025-03-24T11:02:02.459155Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"tuned_model_name = 'inclinedadarsh/gemma-3-1b-nl-to-regex'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:02:36.173285Z","iopub.execute_input":"2025-03-24T11:02:36.173638Z","iopub.status.idle":"2025-03-24T11:02:36.178261Z","shell.execute_reply.started":"2025-03-24T11:02:36.173611Z","shell.execute_reply":"2025-03-24T11:02:36.177397Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    tuned_model_name,\n    device_map='auto',\n    torch_dtype=torch.float16,\n    attn_implementation='eager'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:02:37.616162Z","iopub.execute_input":"2025-03-24T11:02:37.616503Z","iopub.status.idle":"2025-03-24T11:02:42.351641Z","shell.execute_reply.started":"2025-03-24T11:02:37.616476Z","shell.execute_reply":"2025-03-24T11:02:42.350779Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/851 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"977912655a33455cb5340282cecfc08b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/26.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a6887954184d038fddc23563d1ac68"}},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(tuned_model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:02:47.160736Z","iopub.execute_input":"2025-03-24T11:02:47.161047Z","iopub.status.idle":"2025-03-24T11:02:50.782705Z","shell.execute_reply.started":"2025-03-24T11:02:47.161015Z","shell.execute_reply":"2025-03-24T11:02:50.781798Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5197a095a274b6d9d2c06ab983594cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe90feb9e52d4cb599377871dbfde25c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"288b9772ac0440e0b591186d099d5865"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9c34638afe4455c84f23620eb087eea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e030e71fbf4ab99e9e78dc5f8d51ba"}},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"from random import randint\nimport re\n\npipe = pipeline('text-generation', model=model, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:02:52.901813Z","iopub.execute_input":"2025-03-24T11:02:52.902124Z","iopub.status.idle":"2025-03-24T11:02:52.908768Z","shell.execute_reply.started":"2025-03-24T11:02:52.902099Z","shell.execute_reply":"2025-03-24T11:02:52.908049Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"rand_idx = randint(0, len(dataset['train']))\ntest_sample = dataset['train'][rand_idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:03:24.453434Z","iopub.execute_input":"2025-03-24T11:03:24.453721Z","iopub.status.idle":"2025-03-24T11:03:24.458774Z","shell.execute_reply.started":"2025-03-24T11:03:24.453700Z","shell.execute_reply":"2025-03-24T11:03:24.458088Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"stop_token_ids = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")]\nprompt = pipe.tokenizer.apply_chat_template(test_sample['messages'][:2], tokenize=False, add_generation_prompt=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:03:26.444000Z","iopub.execute_input":"2025-03-24T11:03:26.444447Z","iopub.status.idle":"2025-03-24T11:03:26.450692Z","shell.execute_reply.started":"2025-03-24T11:03:26.444411Z","shell.execute_reply":"2025-03-24T11:03:26.449746Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"outputs = pipe(prompt, max_new_tokens=256, do_sample=False, temperature=0.1, top_k=50, top_p=0.1, eos_token_id=stop_token_ids, disable_compile=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:03:27.642130Z","iopub.execute_input":"2025-03-24T11:03:27.642440Z","iopub.status.idle":"2025-03-24T11:03:29.599850Z","shell.execute_reply.started":"2025-03-24T11:03:27.642416Z","shell.execute_reply":"2025-03-24T11:03:29.599132Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:03:34.372981Z","iopub.execute_input":"2025-03-24T11:03:34.373316Z","iopub.status.idle":"2025-03-24T11:03:34.379690Z","shell.execute_reply.started":"2025-03-24T11:03:34.373290Z","shell.execute_reply":"2025-03-24T11:03:34.378900Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': '<bos><start_of_turn>user\\nYou are a helpful natural language to regex converter. The user will provide some prompt, and you have to create a regex according to it.\\n\\nlines containing at least 2 words<end_of_turn>\\n<start_of_turn>model\\n(.*\\\\b[A-Za-z]+\\\\b.*){2}'}]"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}