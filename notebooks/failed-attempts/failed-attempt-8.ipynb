{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:37:09.900746Z","iopub.execute_input":"2025-03-21T18:37:09.900964Z","iopub.status.idle":"2025-03-21T18:37:10.663308Z","shell.execute_reply.started":"2025-03-21T18:37:09.900942Z","shell.execute_reply":"2025-03-21T18:37:10.662259Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:37:40.268233Z","iopub.execute_input":"2025-03-21T18:37:40.268759Z","iopub.status.idle":"2025-03-21T18:37:40.273115Z","shell.execute_reply.started":"2025-03-21T18:37:40.268728Z","shell.execute_reply":"2025-03-21T18:37:40.272064Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dataset = load_dataset('tatsu-lab/alpaca')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:38:14.514763Z","iopub.execute_input":"2025-03-21T18:38:14.515225Z","iopub.status.idle":"2025-03-21T18:38:17.827950Z","shell.execute_reply.started":"2025-03-21T18:38:14.515187Z","shell.execute_reply":"2025-03-21T18:38:17.827078Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"640639b2d3f84fd18de59ecaaac6c79d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-a09b74b3ef9c3b56.parquet:   0%|          | 0.00/24.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bde8390ff3f4239a452ccd82d03deb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/52002 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"273dcbef03964fff89f22fa201a5dcf9"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:40:09.965575Z","iopub.execute_input":"2025-03-21T18:40:09.965902Z","iopub.status.idle":"2025-03-21T18:40:09.972035Z","shell.execute_reply.started":"2025-03-21T18:40:09.965878Z","shell.execute_reply":"2025-03-21T18:40:09.971157Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'instruction': 'Give three tips for staying healthy.',\n 'input': '',\n 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.',\n 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from transformers import AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:51:47.553297Z","iopub.execute_input":"2025-03-21T18:51:47.553755Z","iopub.status.idle":"2025-03-21T18:51:56.945949Z","shell.execute_reply.started":"2025-03-21T18:51:47.553720Z","shell.execute_reply":"2025-03-21T18:51:56.944883Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859f9cc482ed44da919a4018d273bd09"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"text = \"Delhi is the capital of India.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:51:59.159928Z","iopub.execute_input":"2025-03-21T18:51:59.160704Z","iopub.status.idle":"2025-03-21T18:51:59.165369Z","shell.execute_reply.started":"2025-03-21T18:51:59.160649Z","shell.execute_reply":"2025-03-21T18:51:59.164089Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:53:06.561586Z","iopub.execute_input":"2025-03-21T18:53:06.562068Z","iopub.status.idle":"2025-03-21T18:53:06.658416Z","shell.execute_reply.started":"2025-03-21T18:53:06.562025Z","shell.execute_reply":"2025-03-21T18:53:06.657509Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-hf', token=HF_TOKEN)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:53:15.350578Z","iopub.execute_input":"2025-03-21T18:53:15.350908Z","iopub.status.idle":"2025-03-21T18:53:16.912157Z","shell.execute_reply.started":"2025-03-21T18:53:15.350882Z","shell.execute_reply":"2025-03-21T18:53:16.911062Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e656f3f70b740b9a5c403cc7b0b212c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f630f5f6909642c09f0a74d34562a393"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36bb40500de5471ab1ecbc422f2eedd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c953daf50574c85bd97a4d971339cb0"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"tokens = tokenizer(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:53:28.688260Z","iopub.execute_input":"2025-03-21T18:53:28.688655Z","iopub.status.idle":"2025-03-21T18:53:28.695967Z","shell.execute_reply.started":"2025-03-21T18:53:28.688626Z","shell.execute_reply":"2025-03-21T18:53:28.694935Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(f\"{tokens=}\")\nprint(f\"{type(tokens)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:54:19.972049Z","iopub.execute_input":"2025-03-21T18:54:19.972447Z","iopub.status.idle":"2025-03-21T18:54:19.977423Z","shell.execute_reply.started":"2025-03-21T18:54:19.972414Z","shell.execute_reply":"2025-03-21T18:54:19.976359Z"}},"outputs":[{"name":"stdout","text":"tokens={'input_ids': [1, 5556, 2918, 338, 278, 7483, 310, 7513, 29889], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\ntype(tokens)=<class 'transformers.tokenization_utils_base.BatchEncoding'>\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"tokens = tokenizer.tokenize(text)\nprint(f\"{tokens=}\")\nprint(f\"{type(tokens)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:54:44.440616Z","iopub.execute_input":"2025-03-21T18:54:44.440952Z","iopub.status.idle":"2025-03-21T18:54:44.447238Z","shell.execute_reply.started":"2025-03-21T18:54:44.440921Z","shell.execute_reply":"2025-03-21T18:54:44.446130Z"}},"outputs":[{"name":"stdout","text":"tokens=['▁Del', 'hi', '▁is', '▁the', '▁capital', '▁of', '▁India', '.']\ntype(tokens)=<class 'list'>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"tokens = tokenizer.encode(text)\nprint(f\"{tokens=}\")\nprint(f\"{type(tokens)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:55:49.475520Z","iopub.execute_input":"2025-03-21T18:55:49.475836Z","iopub.status.idle":"2025-03-21T18:55:49.482069Z","shell.execute_reply.started":"2025-03-21T18:55:49.475811Z","shell.execute_reply":"2025-03-21T18:55:49.480865Z"}},"outputs":[{"name":"stdout","text":"tokens=[1, 5556, 2918, 338, 278, 7483, 310, 7513, 29889]\ntype(tokens)=<class 'list'>\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"text = \"<user>what's 2+2?<assistant>it's 4\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:56:23.419352Z","iopub.execute_input":"2025-03-21T18:56:23.419682Z","iopub.status.idle":"2025-03-21T18:56:23.424118Z","shell.execute_reply.started":"2025-03-21T18:56:23.419656Z","shell.execute_reply":"2025-03-21T18:56:23.422838Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"tokens = tokenizer.tokenize(text)\nprint(f\"{tokens=}\")\nprint(f\"{type(tokens)=}\")\nprint(f\"{len(tokens)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:56:59.965307Z","iopub.execute_input":"2025-03-21T18:56:59.965668Z","iopub.status.idle":"2025-03-21T18:56:59.971621Z","shell.execute_reply.started":"2025-03-21T18:56:59.965639Z","shell.execute_reply":"2025-03-21T18:56:59.970472Z"}},"outputs":[{"name":"stdout","text":"tokens=['▁<', 'user', '>', 'what', \"'\", 's', '▁', '2', '+', '2', '?', '<', 'ass', 'istant', '>', 'it', \"'\", 's', '▁', '4']\ntype(tokens)=<class 'list'>\nlen(tokens)=20\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"tokens = tokenizer(text)\nprint(f\"{tokens=}\")\nprint(f\"{type(tokens)=}\")\nprint(f\"{len(tokens.input_ids)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:57:14.645041Z","iopub.execute_input":"2025-03-21T18:57:14.645393Z","iopub.status.idle":"2025-03-21T18:57:14.651915Z","shell.execute_reply.started":"2025-03-21T18:57:14.645367Z","shell.execute_reply":"2025-03-21T18:57:14.650777Z"}},"outputs":[{"name":"stdout","text":"tokens={'input_ids': [1, 529, 1792, 29958, 5816, 29915, 29879, 29871, 29906, 29974, 29906, 29973, 29966, 465, 22137, 29958, 277, 29915, 29879, 29871, 29946], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\ntype(tokens)=<class 'transformers.tokenization_utils_base.BatchEncoding'>\nlen(tokens.input_ids)=21\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"tokens = tokenizer.encode(text)\nprint(f\"{tokens=}\")\nprint(f\"{type(tokens)=}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:57:32.546833Z","iopub.execute_input":"2025-03-21T18:57:32.547177Z","iopub.status.idle":"2025-03-21T18:57:32.553624Z","shell.execute_reply.started":"2025-03-21T18:57:32.547123Z","shell.execute_reply":"2025-03-21T18:57:32.552209Z"}},"outputs":[{"name":"stdout","text":"tokens=[1, 529, 1792, 29958, 5816, 29915, 29879, 29871, 29906, 29974, 29906, 29973, 29966, 465, 22137, 29958, 277, 29915, 29879, 29871, 29946]\ntype(tokens)=<class 'list'>\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"tokenizer.decode([])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T18:58:50.366904Z","iopub.execute_input":"2025-03-21T18:58:50.367263Z","iopub.status.idle":"2025-03-21T18:58:50.373106Z","shell.execute_reply.started":"2025-03-21T18:58:50.367235Z","shell.execute_reply":"2025-03-21T18:58:50.372275Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'b'"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"tokenizer.pad_token = '<pad>'\ntokenizer('hello world', padding='max_length', max_length=100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:01:17.399830Z","iopub.execute_input":"2025-03-21T19:01:17.400178Z","iopub.status.idle":"2025-03-21T19:01:17.407347Z","shell.execute_reply.started":"2025-03-21T19:01:17.400120Z","shell.execute_reply":"2025-03-21T19:01:17.406229Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [1, 22172, 3186, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"tokenizer.decode([0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:01:24.598508Z","iopub.execute_input":"2025-03-21T19:01:24.598847Z","iopub.status.idle":"2025-03-21T19:01:24.604693Z","shell.execute_reply.started":"2025-03-21T19:01:24.598822Z","shell.execute_reply":"2025-03-21T19:01:24.603749Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"'<unk>'"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"tokenizer.encode('hello world')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:06:09.863505Z","iopub.execute_input":"2025-03-21T19:06:09.863897Z","iopub.status.idle":"2025-03-21T19:06:09.869643Z","shell.execute_reply.started":"2025-03-21T19:06:09.863869Z","shell.execute_reply":"2025-03-21T19:06:09.868708Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"[1, 22172, 3186]"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"tokenizer.encode('hello world', return_tensors='pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:06:22.253943Z","iopub.execute_input":"2025-03-21T19:06:22.254307Z","iopub.status.idle":"2025-03-21T19:06:22.306409Z","shell.execute_reply.started":"2025-03-21T19:06:22.254275Z","shell.execute_reply":"2025-03-21T19:06:22.305413Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"tensor([[    1, 22172,  3186]])"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"tokenizer.encode('hello world', return_tensors='tf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:06:38.455496Z","iopub.execute_input":"2025-03-21T19:06:38.455868Z","iopub.status.idle":"2025-03-21T19:06:38.501834Z","shell.execute_reply.started":"2025-03-21T19:06:38.455838Z","shell.execute_reply":"2025-03-21T19:06:38.500830Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[    1, 22172,  3186]], dtype=int32)>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"inputs = tokenizer([\"Hello\", \"Hi there how are you\"], return_tensors=\"pt\")\nprint(inputs.input_ids.shape)  # (2, 5) if padded to length 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:21:05.391057Z","iopub.execute_input":"2025-03-21T19:21:05.391446Z","iopub.status.idle":"2025-03-21T19:21:05.443682Z","shell.execute_reply.started":"2025-03-21T19:21:05.391382Z","shell.execute_reply":"2025-03-21T19:21:05.442231Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mas_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 6)","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-79d20d47e2ea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Hello\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Hi there how are you\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (2, 5) if padded to length 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2859\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2860\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2946\u001b[0m                 )\n\u001b[1;32m   2947\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2948\u001b[0;31m             return self.batch_encode_plus(\n\u001b[0m\u001b[1;32m   2949\u001b[0m                 \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2950\u001b[0m                 \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3148\u001b[0m         )\n\u001b[1;32m   3149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3150\u001b[0;31m         return self._batch_encode_plus(\n\u001b[0m\u001b[1;32m   3151\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3152\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msanitized_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eventual_warn_about_too_long_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitized_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitized_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     def _encode_plus(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    791\u001b[0m                         \u001b[0;34m\"Please see if a fast version of this tokenizer is available to have this feature available.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                     ) from e\n\u001b[0;32m--> 793\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    794\u001b[0m                     \u001b[0;34m\"Unable to create tensor, you should probably activate truncation and/or padding with\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m                     \u001b[0;34m\" 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."],"ename":"ValueError","evalue":"Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).","output_type":"error"}],"execution_count":58},{"cell_type":"code","source":"inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:20:53.634616Z","iopub.execute_input":"2025-03-21T19:20:53.634979Z","iopub.status.idle":"2025-03-21T19:20:53.642596Z","shell.execute_reply.started":"2025-03-21T19:20:53.634949Z","shell.execute_reply":"2025-03-21T19:20:53.641513Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[    1, 15043,     0,     0,     0,     0],\n        [    1,  6324,   727,   920,   526,   366]]), 'attention_mask': tensor([[1, 1, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1]])}"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:35:11.121889Z","iopub.execute_input":"2025-03-21T19:35:11.122227Z","iopub.status.idle":"2025-03-21T19:35:19.818258Z","shell.execute_reply.started":"2025-03-21T19:35:11.122198Z","shell.execute_reply":"2025-03-21T19:35:19.817062Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.3\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, BitsAndBytesConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:35:39.803545Z","iopub.execute_input":"2025-03-21T19:35:39.803919Z","iopub.status.idle":"2025-03-21T19:35:39.808738Z","shell.execute_reply.started":"2025-03-21T19:35:39.803890Z","shell.execute_reply":"2025-03-21T19:35:39.807543Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:42:45.917955Z","iopub.execute_input":"2025-03-21T19:42:45.918364Z","iopub.status.idle":"2025-03-21T19:42:45.922882Z","shell.execute_reply.started":"2025-03-21T19:42:45.918329Z","shell.execute_reply":"2025-03-21T19:42:45.921778Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    'TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n    quantization_config=bnb_config,\n    token=HF_TOKEN\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:42:46.472299Z","iopub.execute_input":"2025-03-21T19:42:46.472745Z","iopub.status.idle":"2025-03-21T19:42:46.579552Z","shell.execute_reply.started":"2025-03-21T19:42:46.472713Z","shell.execute_reply":"2025-03-21T19:42:46.578174Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-5518e2a9122f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnb_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHF_TOKEN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3669\u001b[0;31m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[1;32m   3670\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3671\u001b[0m                 \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_bnb_8bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m             )\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0;34m\"Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             )\n","\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`"],"ename":"ImportError","evalue":"Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`","output_type":"error"}],"execution_count":70},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}