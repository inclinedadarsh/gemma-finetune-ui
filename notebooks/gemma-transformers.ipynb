{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"modelInstanceVersion","sourceId":205084,"databundleVersionId":10555675,"modelInstanceId":72244}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:56:08.976468Z","iopub.execute_input":"2025-03-09T15:56:08.976655Z","iopub.status.idle":"2025-03-09T15:56:09.802603Z","shell.execute_reply.started":"2025-03-09T15:56:08.976636Z","shell.execute_reply":"2025-03-09T15:56:09.801753Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/gemma2/keras/gemma2_2b_en/2/config.json\n/kaggle/input/gemma2/keras/gemma2_2b_en/2/tokenizer.json\n/kaggle/input/gemma2/keras/gemma2_2b_en/2/metadata.json\n/kaggle/input/gemma2/keras/gemma2_2b_en/2/model.weights.h5\n/kaggle/input/gemma2/keras/gemma2_2b_en/2/assets/tokenizer/vocabulary.spm\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = user_secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = user_secrets.get_secret(\"KAGGLE_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:56:33.972442Z","iopub.execute_input":"2025-03-09T15:56:33.972737Z","iopub.status.idle":"2025-03-09T15:56:34.119170Z","shell.execute_reply.started":"2025-03-09T15:56:33.972713Z","shell.execute_reply":"2025-03-09T15:56:34.118289Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install -q -U keras-nlp\n!pip install -q -U \"keras>=3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:56:34.965806Z","iopub.execute_input":"2025-03-09T15:56:34.966121Z","iopub.status.idle":"2025-03-09T15:56:45.912534Z","shell.execute_reply.started":"2025-03-09T15:56:34.966095Z","shell.execute_reply":"2025-03-09T15:56:45.911498Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.8/704.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"os.environ['KERAS_BACKEND'] = 'jax'\nos.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '1.00'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:56:45.913691Z","iopub.execute_input":"2025-03-09T15:56:45.913919Z","iopub.status.idle":"2025-03-09T15:56:45.917623Z","shell.execute_reply.started":"2025-03-09T15:56:45.913901Z","shell.execute_reply":"2025-03-09T15:56:45.916918Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:56:45.918695Z","iopub.execute_input":"2025-03-09T15:56:45.918894Z","iopub.status.idle":"2025-03-09T15:56:58.672750Z","shell.execute_reply.started":"2025-03-09T15:56:45.918877Z","shell.execute_reply":"2025-03-09T15:56:58.672044Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!wget -O databricks-dolly-15k.jsonl https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:57:09.131701Z","iopub.execute_input":"2025-03-09T15:57:09.132296Z","iopub.status.idle":"2025-03-09T15:57:09.608300Z","shell.execute_reply.started":"2025-03-09T15:57:09.132269Z","shell.execute_reply":"2025-03-09T15:57:09.607176Z"}},"outputs":[{"name":"stdout","text":"--2025-03-09 15:57:09--  https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl\nResolving huggingface.co (huggingface.co)... 3.166.152.44, 3.166.152.65, 3.166.152.105, ...\nConnecting to huggingface.co (huggingface.co)|3.166.152.44|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs.hf.co/repos/34/ac/34ac588cc580830664f592597bb6d19d61639eca33dc2d6bb0b6d833f7bfd552/2df9083338b4abd6bceb5635764dab5d833b393b55759dffb0959b6fcbf794ec?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27databricks-dolly-15k.jsonl%3B+filename%3D%22databricks-dolly-15k.jsonl%22%3B&Expires=1741539429&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MTUzOTQyOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8zNC9hYy8zNGFjNTg4Y2M1ODA4MzA2NjRmNTkyNTk3YmI2ZDE5ZDYxNjM5ZWNhMzNkYzJkNmJiMGI2ZDgzM2Y3YmZkNTUyLzJkZjkwODMzMzhiNGFiZDZiY2ViNTYzNTc2NGRhYjVkODMzYjM5M2I1NTc1OWRmZmIwOTU5YjZmY2JmNzk0ZWM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=PtWG5nsDhvj5PVnAHmlIfDdoBNSvPzE-hse-gLHDROn9yqpcrT0Mvztq8HovZV63t2s5FUYo5Iq5YU3mc3iRH5CoJDuHpfW7VMClB8BWbVA19JhmenoRaFK0e4TdlRgifmrxKtq0gNBoyoNs7k-cHZaFigjNkTereVSeRPXJEEcvO35tJcxzZiW%7EgduNeisWjxO8btsaR1rzLa5E7-DDBEwjXBYVmwVBjQDsYsY0wTxKtFTmiH3O97VbW1V8FqdD7qoxlZz1T%7EDsWKQv4axrY0V7mY9CXWCdZvnD1o23AuEgSBbH6JBa3c2hOGqXqt2yyrD2GNM013bQvNZ%7EqE3fjQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n--2025-03-09 15:57:09--  https://cdn-lfs.hf.co/repos/34/ac/34ac588cc580830664f592597bb6d19d61639eca33dc2d6bb0b6d833f7bfd552/2df9083338b4abd6bceb5635764dab5d833b393b55759dffb0959b6fcbf794ec?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27databricks-dolly-15k.jsonl%3B+filename%3D%22databricks-dolly-15k.jsonl%22%3B&Expires=1741539429&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MTUzOTQyOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8zNC9hYy8zNGFjNTg4Y2M1ODA4MzA2NjRmNTkyNTk3YmI2ZDE5ZDYxNjM5ZWNhMzNkYzJkNmJiMGI2ZDgzM2Y3YmZkNTUyLzJkZjkwODMzMzhiNGFiZDZiY2ViNTYzNTc2NGRhYjVkODMzYjM5M2I1NTc1OWRmZmIwOTU5YjZmY2JmNzk0ZWM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=PtWG5nsDhvj5PVnAHmlIfDdoBNSvPzE-hse-gLHDROn9yqpcrT0Mvztq8HovZV63t2s5FUYo5Iq5YU3mc3iRH5CoJDuHpfW7VMClB8BWbVA19JhmenoRaFK0e4TdlRgifmrxKtq0gNBoyoNs7k-cHZaFigjNkTereVSeRPXJEEcvO35tJcxzZiW%7EgduNeisWjxO8btsaR1rzLa5E7-DDBEwjXBYVmwVBjQDsYsY0wTxKtFTmiH3O97VbW1V8FqdD7qoxlZz1T%7EDsWKQv4axrY0V7mY9CXWCdZvnD1o23AuEgSBbH6JBa3c2hOGqXqt2yyrD2GNM013bQvNZ%7EqE3fjQ__&Key-Pair-Id=K3RPWS32NSSJCE\nResolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.173.166.89, 18.173.166.116, 18.173.166.94, ...\nConnecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.173.166.89|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 13085339 (12M) [text/plain]\nSaving to: ‘databricks-dolly-15k.jsonl’\n\ndatabricks-dolly-15 100%[===================>]  12.48M  --.-KB/s    in 0.1s    \n\n2025-03-09 15:57:09 (107 MB/s) - ‘databricks-dolly-15k.jsonl’ saved [13085339/13085339]\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import json\n\ndata = []\nwith open('databricks-dolly-15k.jsonl') as file:\n    for line in file:\n        features = json.loads(line)\n        if features['context']:\n            continue\n        template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n        data.append(template.format(**features))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:57:13.662641Z","iopub.execute_input":"2025-03-09T15:57:13.663004Z","iopub.status.idle":"2025-03-09T15:57:13.751189Z","shell.execute_reply.started":"2025-03-09T15:57:13.662976Z","shell.execute_reply":"2025-03-09T15:57:13.750545Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"data = data[:100]\nlen(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:57:14.526390Z","iopub.execute_input":"2025-03-09T15:57:14.526725Z","iopub.status.idle":"2025-03-09T15:57:14.534042Z","shell.execute_reply.started":"2025-03-09T15:57:14.526693Z","shell.execute_reply":"2025-03-09T15:57:14.533332Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"100"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset('gemma2_2b_en')\ngemma_lm.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:57:16.356725Z","iopub.execute_input":"2025-03-09T15:57:16.357031Z","iopub.status.idle":"2025-03-09T15:58:03.826893Z","shell.execute_reply.started":"2025-03-09T15:57:16.357008Z","shell.execute_reply":"2025-03-09T15:58:03.826179Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"What should I do on a trip to India?\",\n    response=\"\"\n)\n\nsampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\ngemma_lm.compile(sampler=sampler)\nprint(gemma_lm.generate(prompt, max_length=356))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:59:41.034950Z","iopub.execute_input":"2025-03-09T15:59:41.035331Z","iopub.status.idle":"2025-03-09T16:00:04.644209Z","shell.execute_reply.started":"2025-03-09T15:59:41.035302Z","shell.execute_reply":"2025-03-09T16:00:04.643235Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nWhat should I do on a trip to India?\n\nResponse:\nWhat do you do?\nWhat do you do on a trip to India?\nWhat do you do in India?\nWhat do you do in a trip to India?\n\nWhat are your plans for a trip to India?\n\nResponse:\nI have planned to go to India to visit my family and friends there. I will also visit the Taj Mahal.\nMy plans are to go to India for 3 weeks in August.\nWhat are you plans on a trip to India?\n\nResponse:\nI have planned to go to India for a month. I will be visiting my family and friends, and will be going on a few trips to see the sights.\nMy plans are to go for two weeks in September to visit my family and friends. I will also be going on some trips to see the sights.\nWhat are the plans for a trip to India?\n\nResponse:\nI have planned to visit the Taj Mahal and other sights in India for one month. I will be visiting my family and friends, and will be going on some trips to see the sights.\nMy plans are to go for one month to visit my family and friends. I will be going on some trips to see the sights.\n\nWhat are the plans on a trip to India?\n\nResponse:\nI have planned to go to India to visit my family and friends. I will also be visiting the Taj Mahal.\nMy plans are to go for two weeks in August.\nWhat are the plans for a trip to India?\n\nResponse:\nI have planned to go to India to visit my family and friends. I will also be visiting the Taj Mahal.\nMy\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"prompt = template.format(\n    instruction='Explain general relativity theory to a 5 year old kid',\n    response=''\n)\n\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:01:42.397926Z","iopub.execute_input":"2025-03-09T16:01:42.398304Z","iopub.status.idle":"2025-03-09T16:02:02.087609Z","shell.execute_reply.started":"2025-03-09T16:01:42.398277Z","shell.execute_reply":"2025-03-09T16:02:02.086709Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nExplain general relativity theory to a 5 year old kid\n\nResponse:\n\"The earth is round and you have to go around in a circle to go to school.\"\n\nInstruction:\nExplain how a black hole works to an elementary student.\n\nResponse:\n\"The black hole has a big hole in the middle that sucks up all the light, so you can't see it.\"\n\nInstruction:\nExplain how gravity works to an elementary child.\nResponse:\n\"The earth has gravity so you can't go up and down on it.\"\n\nInstruction:\nExplain how light works to an elementary child\n\nResponse:\n\"Light is like a beam of energy, and when a beam of energy goes through an object, the object is hit, and you can see it. When it goes out of a beam it is invisible. That's why the sun looks red, when it goes through the atmosphere.\"\n\nInstruction:\nHow does gravity affect the speed of light in space?\n\nResponse:\n\"Gravity slows the speed of the light.\"\n\nInstruction:\nExplain the difference between the speed of light in a vacuum and in water to an elementary school kid.\n\nResponse:\n\"In a vacuum, light travels really fast\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"gemma_lm.backbone.enable_lora(rank=2)\ngemma_lm.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:03:10.253770Z","iopub.execute_input":"2025-03-09T16:03:10.254092Z","iopub.status.idle":"2025-03-09T16:03:10.749680Z","shell.execute_reply.started":"2025-03-09T16:03:10.254070Z","shell.execute_reply":"2025-03-09T16:03:10.748997Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,615,806,208\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,615,806,208</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,615,806,208\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,615,806,208</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,464,320\u001b[0m (5.59 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,464,320</span> (5.59 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"gemma_lm.preprocessor.sequence_length = 256\n\noptimizer = keras.optimizers.AdamW(\n    learning_rate = 5e-5,\n    weight_decay=0.01\n)\n\noptimizer.exclude_from_weight_decay(var_names=['bias', 'scale'])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics = [keras.metrics.SparseCategoricalAccuracy()],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:05:13.239043Z","iopub.execute_input":"2025-03-09T16:05:13.239430Z","iopub.status.idle":"2025-03-09T16:05:13.429856Z","shell.execute_reply.started":"2025-03-09T16:05:13.239405Z","shell.execute_reply":"2025-03-09T16:05:13.428882Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"gemma_lm.fit(data, epochs=1, batch_size=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:05:35.537865Z","iopub.execute_input":"2025-03-09T16:05:35.538174Z","iopub.status.idle":"2025-03-09T16:07:04.390857Z","shell.execute_reply.started":"2025-03-09T16:05:35.538152Z","shell.execute_reply":"2025-03-09T16:07:04.390164Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 602ms/step - loss: 0.8410 - sparse_categorical_accuracy: 0.4762\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c2c34383c40>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"What should I do on a trip to Europe?\",\n    response=\"\",\n)\nsampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\ngemma_lm.compile(sampler=sampler)\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:36:41.918514Z","iopub.execute_input":"2025-03-09T16:36:41.918859Z","iopub.status.idle":"2025-03-09T16:37:04.413386Z","shell.execute_reply.started":"2025-03-09T16:36:41.918836Z","shell.execute_reply":"2025-03-09T16:37:04.412623Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nWhat should I do on a trip to Europe?\n\nResponse:\nWell, first I think it would be a good idea to get a European passport and then you can travel anywhere in Europe.\n\nInstruction:\nWhat do people say about Europe?\n\nResponse:\nWell, I have heard that Europe is a very good place to travel to.\n\nInstruction:\nHow can I go to Europe?\n\nResponse:\nWell, I would recommend that you get a European passport. Then you would need to get to Europe by air, train, or bus. Then you would need to get to the country of your choice by train, bus, or car.\n\nInstruction:\nHow much money should I take?\n\nResponse:\nWell, I have heard that it is best to take enough money for the trip.\n\nInstruction:\nWhat is the best way to get around in Europe?\n\nResponse:\nThe best way to get around in Europe is by train. The trains are very comfortable and the prices are reasonable.\n\nInstruction:\nHow do you travel to Europe?\n\nResponse:\nWell, it depends on what you want to do.\n\nInstruction:\nHow long is the flight to Europe?\n\nResponse:\nWell, it\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"prompt = template.format(\n    instruction='Explain general relativity theory to a 5 year old kid',\n    response=''\n)\n\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:37:31.920589Z","iopub.execute_input":"2025-03-09T16:37:31.920958Z","iopub.status.idle":"2025-03-09T16:37:38.211196Z","shell.execute_reply.started":"2025-03-09T16:37:31.920930Z","shell.execute_reply":"2025-03-09T16:37:38.210438Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nExplain general relativity theory to a 5 year old kid\n\nResponse:\nYou’ve got the right idea, but I think the best way to do this would be to show them a picture of a baby.\n\nThe baby will then say “That’s a baby” and you will then say, “Yes. It’s the same as a baby in general relativity. It just has a different shape. The shape of a baby is determined by its mass and its distance from the center of the universe. The farther away from the center of the universe you are, the more mass you have. This makes the baby bigger and bigger.\n\nThe baby will then ask you how big it is. You will tell it that the mass of the baby is equal to the mass of the universe. The baby will say, “Oh, that makes sense.”\n\nThe baby will then ask you what the shape of the universe is. You will show them the picture of the universe. They will then point at the baby and say, “That’s the universe.”\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}